<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Stochastic Analytic Continuation 2 · ACFlow</title><meta name="title" content="Stochastic Analytic Continuation 2 · ACFlow"/><meta property="og:title" content="Stochastic Analytic Continuation 2 · ACFlow"/><meta property="twitter:title" content="Stochastic Analytic Continuation 2 · ACFlow"/><meta name="description" content="Documentation for ACFlow."/><meta property="og:description" content="Documentation for ACFlow."/><meta property="twitter:description" content="Documentation for ACFlow."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../index.html">ACFlow</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../index.html">Home</a></li><li><span class="tocitem">Introduction</span><ul><li><a class="tocitem" href="../intro/background.html">Background</a></li><li><a class="tocitem" href="../intro/ack.html">Acknowledgements</a></li><li><a class="tocitem" href="../intro/cite.html">Citation</a></li></ul></li><li><span class="tocitem">Manual</span><ul><li><a class="tocitem" href="../man/feature.html">Main Features</a></li><li><a class="tocitem" href="../man/impl.html">Implementations</a></li><li><a class="tocitem" href="../man/install.html">Installation</a></li><li><a class="tocitem" href="../man/run.html">Running Modes</a></li><li><a class="tocitem" href="../man/input.html">Input Files</a></li><li><a class="tocitem" href="../man/output.html">Output Files</a></li><li><a class="tocitem" href="../man/param.html">Parameters</a></li><li><a class="tocitem" href="../man/tricks.html">Tricks and tips</a></li></ul></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../examples/sigma.html">Matsubara Self-Energy Function</a></li><li><a class="tocitem" href="../examples/green1.html">Matsubara Green&#39;s Function</a></li><li><a class="tocitem" href="../examples/green2.html">Imaginary Time Green&#39;s Function</a></li><li><a class="tocitem" href="../examples/current.html">Current-Current Correlation Function</a></li></ul></li><li><span class="tocitem">Theory</span><ul><li><a class="tocitem" href="basic.html">Basic Principles</a></li><li><a class="tocitem" href="maxent.html">Maximum Entropy Method</a></li><li><a class="tocitem" href="nac.html">Nevanlinna Analytical Continuation</a></li><li><a class="tocitem" href="sac1.html">Stochastic Analytic Continuation 1</a></li><li class="is-active"><a class="tocitem" href="sac2.html">Stochastic Analytic Continuation 2</a><ul class="internal"><li><a class="tocitem" href="#Beach&#39;s-Algorithm"><span>Beach&#39;s Algorithm</span></a></li><li><a class="tocitem" href="#Classic-Fields"><span>Classic Fields</span></a></li><li><a class="tocitem" href="#Monte-Carlo-Sampling"><span>Monte Carlo Sampling</span></a></li><li><a class="tocitem" href="#Parallel-Tempering"><span>Parallel Tempering</span></a></li><li><a class="tocitem" href="#Critical-Inverse-Temperature"><span>Critical Inverse Temperature</span></a></li><li><a class="tocitem" href="#Likelihood-Function"><span>Likelihood Function</span></a></li><li><a class="tocitem" href="#Relevant-parameters"><span>Relevant parameters</span></a></li></ul></li><li><a class="tocitem" href="som.html">Stochastic Optimization Method</a></li><li><a class="tocitem" href="spx.html">Stochastic Pole Expansion</a></li><li><a class="tocitem" href="reference.html">References</a></li></ul></li><li><span class="tocitem">Library</span><ul><li><a class="tocitem" href="../library/outline.html">Outline</a></li><li><a class="tocitem" href="../library/acflow.html">ACFlow</a></li><li><a class="tocitem" href="../library/global.html">Constants</a></li><li><a class="tocitem" href="../library/type.html">Types</a></li><li><a class="tocitem" href="../library/base.html">Core</a></li><li><a class="tocitem" href="../library/solver.html">Solvers</a></li><li><a class="tocitem" href="../library/grid.html">Grids</a></li><li><a class="tocitem" href="../library/mesh.html">Meshes</a></li><li><a class="tocitem" href="../library/model.html">Models</a></li><li><a class="tocitem" href="../library/kernel.html">Kernels</a></li><li><a class="tocitem" href="../library/config.html">Configuration</a></li><li><a class="tocitem" href="../library/inout.html">Input and output</a></li><li><a class="tocitem" href="../library/math.html">Math</a></li><li><a class="tocitem" href="../library/util.html">Utilities</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Theory</a></li><li class="is-active"><a href="sac2.html">Stochastic Analytic Continuation 2</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="sac2.html">Stochastic Analytic Continuation 2</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/huangli712/ACFlow" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="sac"><a class="docs-heading-anchor" href="#sac">Stochastic Analytic Continuation 2</a><a id="sac-1"></a><a class="docs-heading-anchor-permalink" href="#sac" title="Permalink"></a></h1><div class="admonition is-info"><header class="admonition-header">Info</header><div class="admonition-body"><p>In principle, for given Green&#39;s function <span>$G$</span>, there exists infinitely many spectral densities <span>$A(\omega)$</span> that can be used to reproduce <span>$G$</span> via <span>$\mathbf{G} = \mathbf{KA}$</span>. The maximum entropy method tries to pick up the most likely spectral function which maximizes <span>$P[A|\bar{G}]$</span> (It actually maximizes <span>$Q$</span>). Here, we would like to introduce an alternative approach, namely the stochastic analytic continuation. It is argued that the weights for all the possible spectral densities are the same if they can give rise to the same <span>$\chi^2$</span>. At first, a sequence of spectral densities will be generated by stochastic method. Then an unbiased thermal average of all possible spectra, Boltzmann weighted according to goodness-of-fit function <span>$\chi^{2}$</span>, produces an average spectrum. Thus sometimes the method was named as average spectrum method or stochastic sampling method in the references. There are several variants for the stochastic analytic continuation. Next we will introduce two representative algorithms as proposed by A. W. Sandvik and K. S. D. Beach, respectively.</p></div></div><h2 id="Beach&#39;s-Algorithm"><a class="docs-heading-anchor" href="#Beach&#39;s-Algorithm">Beach&#39;s Algorithm</a><a id="Beach&#39;s-Algorithm-1"></a><a class="docs-heading-anchor-permalink" href="#Beach&#39;s-Algorithm" title="Permalink"></a></h2><p>K. S. D. Beach proposed another variant of stochastic analytic continuation in 2004. In his approach, the analytic continuation problem is mapped into a system of interacting classic fields at first. Then the classic field is sampled using Monte Carlo method to obtain the final solution. He concluded that the maximum entropy method is simply the mean field limit of the stochastic analytic continuation. Next, this algorithm will be explained concisely.</p><h2 id="Classic-Fields"><a class="docs-heading-anchor" href="#Classic-Fields">Classic Fields</a><a id="Classic-Fields-1"></a><a class="docs-heading-anchor-permalink" href="#Classic-Fields" title="Permalink"></a></h2><p>Recalled that the goodness-of-fit functional <span>$\chi^{2}[A]$</span> measures how closely the Green&#39;s function generated from <span>$A(\omega)$</span> matches the raw input data. Its expression is rewritten as follows:</p><p class="math-container">\[\begin{equation}
\chi^{2}[A] = \int^{\beta}_{0} \frac{1}{\sigma(\tau)^2}
\left|\int d\omega~K(\tau,\omega) A(\omega) - \bar{G}(\tau)\right|^2 d\tau.
\end{equation}\]</p><p>At first, a new variable <span>$x$</span> is introduced. The relation between <span>$x$</span> and <span>$\omega$</span> is:</p><p class="math-container">\[\begin{equation}
x = \phi(\omega) = \int^{\omega}_{-\infty} d\omega&#39;~m(\omega&#39;),
\end{equation}\]</p><p>where <span>$m(\omega)$</span> denotes default model function. Clearly, the <span>$\phi(\omega)$</span> function defines a smooth mapping from <span>$\mathbf{R} \to [0,1]$</span>. Since <span>$\omega = \phi^{-1}(x)$</span>, a dimensionless classic field <span>$n(x)$</span> is created:</p><p class="math-container">\[\begin{equation}
n(x) = \frac{A(\phi^{-1}(x))}{m(\phi^{-1}(x))}.
\end{equation}\]</p><p>It is easy to prove that both <span>$n(x)$</span> and <span>$A(\omega)$</span> obey similar normalization condition:</p><p class="math-container">\[\begin{equation}
\int d\omega~A(\omega) = \int^{1}_0 dx~n(x) = 1.
\end{equation}\]</p><p>Next, in analogy with the goodness-of-fit functional <span>$\chi^2[A]$</span>, the Hamiltonian for the system of classic field <span>$\{n(x)\}$</span> can be defined as follows:</p><p class="math-container">\[\begin{equation}
H[n(x)] = \int^{\beta}_0 \frac{d\tau}{\sigma(\tau)^2}
\left|
\int^{1}_0 dx~K(\tau,x) n(x) - \bar{G}(\tau)
\right|.
\end{equation}\]</p><p>Supposing <span>$\alpha$</span> is an inverse temperature of the system, then the partition function <span>$Z$</span> is:</p><p class="math-container">\[\begin{equation}
Z = \int \mathcal{D}n~e^{-\alpha H[n]},
\end{equation}\]</p><p>where</p><p class="math-container">\[\begin{equation}
\int \mathcal{D}n =
\int^{\infty}_0 \left[\prod_x dn(x)\right]
\delta\left(\int^{1}_0 dx~n(x) - 1\right).
\end{equation}\]</p><p>The thermally averaged value of the classic field is:</p><p class="math-container">\[\begin{equation}
\langle n(x) \rangle = \frac{1}{Z} \int \mathcal{D}n~n(x) e^{-\alpha H[n]}.
\end{equation}\]</p><p>Finally, according to the definition of the classic field, the averaged spectral density <span>$\langle A(\omega) \rangle$</span> can be expressed as:</p><p class="math-container">\[\begin{equation}
\langle A(\omega) \rangle = \langle n(\phi(\omega)) \rangle m(\omega).
\end{equation}\]</p><p>So, by introducing the classic field <span>$\{n(x)\}$</span>, the analytic continuation problem is converted into a statistical sampling of the classic field, which is easily solved by using the Monte Carlo method.</p><h2 id="Monte-Carlo-Sampling"><a class="docs-heading-anchor" href="#Monte-Carlo-Sampling">Monte Carlo Sampling</a><a id="Monte-Carlo-Sampling-1"></a><a class="docs-heading-anchor-permalink" href="#Monte-Carlo-Sampling" title="Permalink"></a></h2><p>Next we clarify how to sample the classic field. Similar to Sandvik&#39;s algorithm, <span>$n(x)$</span> is parameterized as a superposition of many <span>$\delta$</span> functions (see Fig.1 for schematic diagram):</p><p class="math-container">\[\begin{equation}
n_{\mathcal{C}} (x) = \sum_i \gamma_i \delta(x - r_i),
\end{equation}\]</p><p>where <span>$\gamma_i$</span> and <span>$r_i$</span> denote amplitude (weight) and position of the <span>$i$</span>-th <span>$\delta$</span> function, respectively. And <span>$\mathcal{C}$</span> means a configuration space formed by a set of <span>$r_i$</span> and <span>$\gamma_i$</span>,</p><p class="math-container">\[\begin{equation}
\mathcal{C} = \{r_i, \gamma_i\}.
\end{equation}\]</p><p>Note that <span>$\gamma_i$</span> and <span>$r_i$</span> satisfy the following constraints:</p><p class="math-container">\[\begin{equation}
\forall i,~\gamma_i &gt; 0,~\sum_i \gamma_i = 1,~ 0 \le r_i \le 1.
\end{equation}\]</p><p>Supposed that there is a transition from <span>$\mathcal{C}$</span> to <span>$\mathcal{C}&#39;$</span> (<span>$\{r_i, \gamma_i\} \to \{r&#39;_i, \gamma&#39;_i\}$</span>):</p><p class="math-container">\[\begin{equation}
r_i \to r&#39;_i =
r_i + \sum_{\lambda \in \Lambda} \delta_{i\lambda} \Delta r_{\lambda},
\end{equation}\]</p><p class="math-container">\[\begin{equation}
\gamma_i \to \gamma&#39;_i =
\gamma_i + \sum_{\lambda \in \Lambda} \delta_{i\lambda} \Delta \gamma_{\lambda},
\end{equation}\]</p><p>where <span>$\Lambda$</span> means a subset of the <span>$\delta$</span> functions, then the Hamiltonian of the system is changed from <span>$H_{\mathcal{C}}$</span> to <span>$H_{\mathcal{C}&#39;}$</span>. According to Eq.(5), <span>$H_\mathcal{C}$</span>, <span>$H_{\mathcal{C}&#39;}$</span>, and their difference <span>$\Delta H$</span> can be calculated by:</p><p class="math-container">\[\begin{equation}
H_{\mathcal{C}} = \int^{\beta}_0 d\tau~h_{\mathcal{C}}(\tau)^2,
\end{equation}\]</p><p class="math-container">\[\begin{equation}
H_{\mathcal{C}&#39;} = \int^{\beta}_0 d\tau
\left[h_{\mathcal{C}}(\tau) + \Delta h(\tau)\right]^2,
\end{equation}\]</p><p class="math-container">\[\begin{equation}
\Delta H = H_{\mathcal{C}&#39;} - H_{\mathcal{C}} =
\int^{\beta}_0 d\tau~\Delta h(\tau)
[2h_{\mathcal{C}}(\tau) + \Delta h(\tau)].
\end{equation}\]</p><p>Here,</p><p class="math-container">\[\begin{equation}
h(\tau) = \frac{1}{\sigma(\tau)} \left[\int^1_0 dx~K(\tau, x)n(x) - \bar{G}(\tau)\right],
\end{equation}\]</p><p>and</p><p class="math-container">\[\begin{equation}
\Delta h(\tau) = \frac{1}{\sigma(\tau)}
\sum_{\lambda \in \Lambda}
\left[
\gamma&#39;_{\lambda} K(\tau,r&#39;_{\lambda}) - \gamma_{\lambda} K(\tau,r_{\lambda})
\right].
\end{equation}\]</p><p>Finally, the transition probability from <span>$\mathcal{C}$</span> to <span>$\mathcal{C}&#39;$</span> reads</p><p class="math-container">\[\begin{equation}
p(C \to C&#39;) = \exp(-\alpha \Delta H).
\end{equation}\]</p><p><img src="../assets/sac.png" alt="sac.png"/></p><p><strong>Figure 1 |</strong> Typical Monte Carlo field configurations for stochastic analytic continuation (K. S. D. Beach&#39;s version). Note that the amplitudes <span>$\{\gamma_i\}$</span> of all the <span>$\delta$</span> functions are not identical. Both amplitudes <span>$\{\gamma_i\}$</span> and positions <span>$\{r_i\}$</span> (<span>$0.0 &lt; r_i &lt; 1.0$</span>) can be sampled by Monte Carlo method.</p><h2 id="Parallel-Tempering"><a class="docs-heading-anchor" href="#Parallel-Tempering">Parallel Tempering</a><a id="Parallel-Tempering-1"></a><a class="docs-heading-anchor-permalink" href="#Parallel-Tempering" title="Permalink"></a></h2><p>The parallel tempering trick is adopted to improve the Monte Carlo algorithm as described above. It is possible to proceed multiple simulations simultaneously for a sequence of inverse temperature parameters <span>$\{\alpha_1, \alpha_2, \cdots, \alpha_N \}$</span>. The ratio for two adjacent <span>$\alpha$</span> parameters is a constant: <span>$\alpha_{p+1} / \alpha_p = R$</span>. Note that the field configurations in all simulations evolve in parallel but not independently. We can swap the field configurations between two adjacent layers. Of course, the detailed balance is always preserved, and each simulation will eventually settle into thermal equilibrium at given <span>$\alpha$</span>. The transition probability of such a global Monte Carlo update is:</p><p class="math-container">\[\begin{equation}
p(\mathcal{C} \to \mathcal{C}&#39;) = \exp[(\alpha_p - \alpha_q)(H_{p} - H_{q})],
\end{equation}\]</p><p>where <span>$p$</span> and <span>$q$</span> are layer indices, and <span>$p = q \pm 1$</span>. Parallel tempering eliminates the need for an initial annealing stage. Another advantage of parallel tempering is that it yields a complete temperature profile of all the important thermodynamic variables (such as specific heat and internal energy), which can be used to estimate the critical <span>$\alpha$</span> and final spectral function <span>$\langle A(\omega) \rangle$</span>.</p><h2 id="Critical-Inverse-Temperature"><a class="docs-heading-anchor" href="#Critical-Inverse-Temperature">Critical Inverse Temperature</a><a id="Critical-Inverse-Temperature-1"></a><a class="docs-heading-anchor-permalink" href="#Critical-Inverse-Temperature" title="Permalink"></a></h2><p>Clearly, <span>$\langle n(x) \rangle$</span> strongly depends on the inverse temperature <span>$\alpha$</span>. How to use these <span>$\alpha$</span>-dependent <span>$\langle n(x) \rangle$</span> to construct the final spectral function? Beach proposed a new algorithm. During parallel tempering process, the internal energy of the system is also measured in addition to <span>$\langle n(x) \rangle$</span>:</p><p class="math-container">\[\begin{equation}
U(\alpha_p) = \langle H [n] \rangle_{\alpha_p}.
\end{equation}\]</p><p>Let us plot <span>$\log_{10}[U(\alpha)]$</span> as a function of <span>$\log_{10} (\alpha)$</span>. We find that <span>$\log_{10}[U(\alpha)]$</span> drops quickly at first when <span>$\log_{10} (\alpha)$</span> increases, and then it approaches to a constant value slowly. The knee in <span>$\log_{10}[U(\alpha)]$</span> function, occurring in the vicinity of <span>$\alpha = \alpha^*$</span> (the corresponding layer index <span>$p = p^{*}$</span>), signals a jump in specific heat (a thermodynamic phase transition). Then the averaged spectral function is constructed by:</p><p class="math-container">\[\begin{equation}
\langle \langle n(x) \rangle \rangle =
\frac{\sum^{N-1}_{p = p*} [U(\alpha_p) - U(\alpha_{p+1})] \langle n(x) \rangle_{\alpha_p}}
{U(\alpha_{p*}) - U(\alpha_N)},
\end{equation}\]</p><p>where <span>$N$</span> is the total number of <span>$\alpha$</span>, and <span>$\alpha_{p*}$</span> (<span>$\equiv \alpha^{*}$</span>) is the critical inverse temperature.</p><h2 id="Likelihood-Function"><a class="docs-heading-anchor" href="#Likelihood-Function">Likelihood Function</a><a id="Likelihood-Function-1"></a><a class="docs-heading-anchor-permalink" href="#Likelihood-Function" title="Permalink"></a></h2><p>Neither of the Sandvik&#39;s and Beach&#39;s algorithms needs extra entropic term to regulate spectral density. All the stochastically generated spectra are treated on the same footing. Thus, the calculated spectral function retains more subtle structures than that obtained by the maximum entropy method. Actually, in stochastic analytic continuation,</p><p class="math-container">\[\begin{equation}
\langle A \rangle = \int \mathcal{D} A~P[A|\bar{G}] A.
\end{equation}\]</p><p>The weight of the candidate spectral function <span>$A$</span> is given by the likelihood function <span>$P[A|\bar{G}]$</span>. Eq.(20) can be viewed as likelihood functions in stochastic analytic continuation.</p><h2 id="Relevant-parameters"><a class="docs-heading-anchor" href="#Relevant-parameters">Relevant parameters</a><a id="Relevant-parameters-1"></a><a class="docs-heading-anchor-permalink" href="#Relevant-parameters" title="Permalink"></a></h2><p>See <a href="../man/param.html#stochac_block">[StochAC] Block</a></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="sac1.html">« Stochastic Analytic Continuation 1</a><a class="docs-footer-nextpage" href="som.html">Stochastic Optimization Method »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="auto">Automatic (OS)</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.1.0 on <span class="colophon-date" title="Thursday 18 July 2024 10:07">Thursday 18 July 2024</span>. Using Julia version 1.8.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
